# Settlement

The settle function can be divided into two main logical parts:

1. Verification
2. Transfer

## Overview

1. The essence of the settlement voucher is a request sent by the user to the provider. Each request contains fee information, signed by the user, and verified and recognized by the provider.
2. To save gas and time, the provider uses zk (Zero-Knowledge) to produce a settlement voucher for multiple requests. This voucher includes:
    1. **proof**: The proof generated by the zk circuit. This proof shows that the provider has verified that the information in the requests matches the information in the public input, satisfying certain inherent relationships (details in [Zk Proof on the Provider Side](#zk-proof-on-the-provider-side)).
    2. **public input**: Information visible to the verifier, representing the constraints in the proof process. It is also the input information needed by the contract to calculate the fee.
3. As the verifier, the contract verifies that the proof and public input provided by the provider meet the agreed logic. It then calculates the fee based on the information in the public input and performs the transfer.

### Verification

The verification process can be divided into three parts:

1. [Zk Proof on the Provider Side](#zk-proof-on-the-provider-side): Performed by the zk component deployed by the provider, outputting proof and public input.
2. [Verification of proof and public input on the contract](#verification-of-proof-and-public-input-on-the-contract).
3. [Additional verification](#additional-verification): Further comparing the public input with specific parameters recorded on the contract to confirm the legality of the public input.

### Zk Proof on the Provider Side

1. Each request contains the following information: nonce, fee, user address, provider address, and signature. These elements represent:

    1. **nonce**: Used to mark the request's uniqueness.
    2. **fee**: The fee for that request.
    3. **user address**: The user's address.
    4. **provider address**: The provider's address.
    5. **signature**: The signature of the above information, using the private key corresponding to the public key in the public input. Each user has a fixed key pair.

2. The provider groups the requests by user and then further groups each user's requests into fixed-size chunks. Requests fewer than the size are padded with zero values. The hardcoded size in the circuit is currently 40. Each such group is referred to as a chunk. For example, if a provider has 90 requests from user A, 50 from user B, and 70 from user C, they will be divided into six groups [40, 40, 10, 40, 10, 40, 30]. Each group will generate a proof and public input.

    1. **proof**: A multi-dimensional array representing the proof result. The specific values do not carry inherent significance.

    2. **public input**: Contains the following information: user address, provider address, initial nonce, final nonce, total fee, and signer public key. These represent:

        1. user address: The user's address.
        2. provider address: The provider's address.
        3. initial nonce: The nonce of the first request in the 40 requests.
        4. final nonce: The nonce of the last request in the 40 requests.
        5. total fee: The total fee of the 40 requests.
        6. signer public key: The public key used to verify each request's signature.

    3. Constraints logic of the proof:

        1. The signer public key in the public input parses each signature to obtain the request's meta information: nonce, fee, user address, and provider address, and verifies it matches the actual request information.
            - This converts the verification of each request's meta information into the verification of the signer's public key in the public input.
        2. The total fee of the 40 requests is equal to the fee in the public input.
            - This converts the verification of the total request fee into the verification of the public input's fee.
        3. The nonces of the 40 requests are sequentially increasing, with the smallest being the initial nonce and the largest being the final nonce in the public input.
            - After each successful settlement, the contract records the final nonce. Therefore, the smallest recorded nonce less than the public input's initial nonce shows that all requests in the settlement fulfill the nonce increasing sequence and are greater than previous requests, preventing double-spend attacks.

### Verification of Proof and Public Input on the Contract

1. The proof generated in the previous step will be combined into the following input structure:

    ```golang
     verifierInput := contract.VerifierInput{
         InProof:     []*big.Int{},
         ProofInputs: []*big.Int{},
         NumChunks:   big.NewInt(0),
         SegmentSize: []*big.Int{},
     }
    ```

    1. **InProof**: Represents the proof array, combined from each chunk's proof.
    2. **ProofInputs**: Represents the public input array, combined from each chunk's public input.
    3. **NumChunks**: The number of chunks.
    4. **SegmentSize**: Though chunks from different users' requests can be intermixed in the zk circuit logic, it is required in subsequent verification that chunks from different users are not interspersed. Each element in SegmentSize represents the length of each segment from the same user in ProofInputs.

2. The contract will batch-verify each proof in verifierInput.

### Additional Verification

Break down ProofInputs into segments according to SegmentSize, where each segment corresponds to one user's chunks, and verify each:

1. Verification for the first chunk:

    1. Based on the user address and provider address in ProofInputs, find the account information on the contract.
    2. Verify the account's signer matches the signer public key field in ProofInputs.
    3. Verify the nonce in the account is less than the initial nonce in ProofInputs.
    4. Record the chunk's fee.

2. Verification for subsequent chunks in the ProofInputs:

    1. Each user address and provider address in the ProofInputs should be consistent with the ones in the first chunk.
    2. The final nonce in each chunk should be less than the initial nonce of the next chunk.
    3. Record the chunk's fee.

3. Calculate the total fee for all chunks. If the account's balance is sufficient, proceed with the [transfer](#transfer).

## Transfer

1. Each account has two funds pools: the "non-refunded funds pool" and the "refunded funds pool."
2. The "refunded funds pool" contains funds that users have requested to refund but the lock time (lock time) has not been reached, so it has not yet been returned to the users.
3. The "refunded funds pool" consists of individual refunds. Each refund has its amount and application time.
4. When transferring, the system first deducts from the "non-refunded funds pool" and then proceeds in reverse chronological order to deduct from each refund in the "refunded funds pool" as needed.

## Deposit and Refund Cancellation Process

When a user deposits funds into their account, the system can optimize gas costs by canceling pending refunds instead of processing them separately. This section describes the optimized deposit process implemented in the fine-tuning contracts.

### Overview

The `depositFund` function handles two scenarios:
1. **Direct deposit**: Simply adds the amount to the account balance
2. **Deposit with refund cancellation**: Cancels pending refunds up to a specified amount before adding new funds

### Refund Cancellation Logic

When `cancelRetrievingAmount` > 0, the system processes pending refunds efficiently:

#### In-Place Processing
The optimization avoids creating new arrays in memory by processing refunds directly in storage:

```solidity
// Process refunds in-place to avoid memory allocation
uint writeIndex = 0;
for (uint i = 0; i < account.refunds.length; i++) {
    Refund storage refund = account.refunds[i];
    // Process refund...
}
```

#### Cancellation Algorithm

For each unprocessed refund, the system determines whether to:

1. **Fully cancel** the refund (if `remainingCancel >= refund.amount`):
   - Marks the refund as processed
   - Deducts the full amount from `pendingRefund`
   - Reduces `remainingCancel` by the refund amount

2. **Partially cancel** the refund (if `0 < remainingCancel < refund.amount`):
   - Reduces the refund amount by `remainingCancel`
   - Deducts `remainingCancel` from `pendingRefund`
   - Sets `remainingCancel` to 0 (no more cancellations)

3. **Keep unchanged** (if `remainingCancel == 0`):
   - The refund remains in the queue unchanged

#### Array Compaction

After processing, unprocessed refunds are compacted to the front of the array:
- Uses a `writeIndex` to track where to place kept refunds
- Moves unprocessed refunds to consecutive positions at the array's start
- Updates the index field for each moved refund

#### Cleanup Strategy

The system employs a lazy cleanup approach:
- Only removes processed refunds from the array when necessary
- Calls `_cleanupRefunds` to pop processed entries from the array's end
- Reduces storage operations and gas costs

### Example Scenario

Consider an account with pending refunds: [100, 200, 150] and `cancelRetrievingAmount = 250`:

1. **First refund (100)**: 
   - 250 ≥ 100 → Fully canceled
   - Remaining: 150

2. **Second refund (200)**:
   - 150 < 200 → Partially canceled to 50
   - Remaining: 0

3. **Third refund (150)**:
   - 0 remaining → Unchanged

## Refund Array Management System

The contract implements a sophisticated refund management system designed for gas efficiency and data integrity.

### Core Data Structure Design

#### Dual-State Array Architecture
Each account maintains a refund array with two logical regions:

- **Active region**: Positions 0 to `validRefundsLength-1` contain currently active refunds
- **Dirty region**: Positions from `validRefundsLength` to `array.length-1` contain processed or stale data

This design separates logical state from physical storage, enabling efficient reuse of memory slots.

#### Valid Length Tracking
The `validRefundsLength` field serves as the boundary marker:
- Acts as both the count of active refunds and the insertion point for new refunds
- Enables O(1) determination of where to place new refund data
- Maintains data consistency across different operations

### Refund Lifecycle Management

#### Creation Strategy
When creating new refunds, the system employs a position reuse strategy:

```solidity
if (account.validRefundsLength < account.refunds.length) {
    // Reuse existing memory slot
    newIndex = account.validRefundsLength;
    account.refunds[newIndex] = Refund(newIndex, amount, block.timestamp, false);
} else {
    // Expand array with new slot
    newIndex = account.refunds.length;
    account.refunds.push(Refund(newIndex, amount, block.timestamp, false));
}
```

This approach prioritizes memory slot reuse to minimize storage expansion costs.

#### Processing Algorithm
The `processRefund` function implements in-place array compaction:

1. **Iteration phase**: Examines each refund for release eligibility based on lock time
2. **Compaction phase**: Moves active refunds to consecutive positions starting from index 0
3. **State update**: Updates `validRefundsLength` to reflect the new active refund count
4. **Cleanup decision**: Applies conditional cleanup based on dirty data volume

#### Cleanup Strategy Framework
The system employs a threshold-based cleanup approach with two operational modes:

**Constants Definition:**
- `MAX_REFUNDS_PER_ACCOUNT = 30`: Hard limit on refunds per account
- `REFUND_CLEANUP_THRESHOLD = 15`: Decision threshold for cleanup strategy selection

**Strategy Selection Logic:**
```solidity
if (dirtyCount >= REFUND_CLEANUP_THRESHOLD) {
    // High dirty count: Physical cleanup more economical
    _cleanupRefunds(account, writeIndex);
} else {
    // Low dirty count: Mark as processed to prevent reprocessing
    for (uint i = writeIndex; i < account.refunds.length; i++) {
        account.refunds[i].processed = true;
    }
}
```

### Design Principles

#### Memory Efficiency
- **In-place processing**: Eliminates temporary array allocations during compaction
- **Slot reuse**: Prioritizes existing memory slots over array expansion
- **Lazy cleanup**: Defers expensive cleanup operations until economically justified

#### Data Integrity
- **Processed flag**: Prevents duplicate processing of the same refund
- **Index consistency**: Maintains correct index values after compaction
- **Boundary enforcement**: Uses `validRefundsLength` to prevent access to stale data

#### Time Ordering Preservation
- **FIFO processing**: Maintains chronological order for refund processing
- **Lock time compliance**: Enforces proper waiting periods before fund release
- **Cancellation sequencing**: Preserves time-based ordering during deposit cancellations

### Algorithmic Complexity

#### Space Complexity
- **Best case**: O(active_refunds) when cleanup is frequent
- **Worst case**: O(MAX_REFUNDS_PER_ACCOUNT) due to hard limits
- **Amortized**: Approaches O(active_refunds) with proper threshold tuning

#### Time Complexity
- **Creation**: O(1) for position reuse, O(1) for expansion
- **Processing**: O(total_refunds) for single pass processing
- **Cleanup**: O(dirty_count) when threshold is exceeded

### Economic Model

The system's economic efficiency stems from:

#### Storage Cost Reduction
- Reusing existing slots avoids new storage allocation costs
- Lazy cleanup amortizes expensive operations across multiple transactions
- In-place processing eliminates memory copy operations

#### Transaction Gas Optimization
- Predictable gas usage through bounded array operations
- Threshold-based decisions optimize for common usage patterns
- Maximum gas consumption remains within safe transaction limits
